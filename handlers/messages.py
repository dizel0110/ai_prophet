import os
import logging
import asyncio
import random
import glob
from datetime import datetime
from aiogram import Router, types, Bot, F
from aiogram.enums import ChatAction
from aiogram.filters import Command, CommandStart
from aiogram.types import WebAppInfo, ReplyKeyboardMarkup, KeyboardButton, InlineKeyboardMarkup, InlineKeyboardButton
from core.ai_engine import get_ai_chat, get_client, reset_chat, get_hf_response
from core.tools import web_search
from config import FALLBACK_MODELS, TEMP_DIR
from google.genai import types as genai_types

logger = logging.getLogger(__name__)
router = Router()
user_settings = {}

def cleanup_file(path):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
    try:
        if path and os.path.exists(path):
            os.remove(path)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {path}")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {path}: {e}")

def cleanup_user_temp(chat_id):
    """–£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    pattern = os.path.join(TEMP_DIR, f"task_{chat_id}_*")
    for f in glob.glob(pattern):
        cleanup_file(f)
    pattern_audio = os.path.join(TEMP_DIR, f"audio_{chat_id}_*")
    for f in glob.glob(pattern_audio):
        cleanup_file(f)

def get_main_menu():
    kb = [
        [KeyboardButton(text="üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"), KeyboardButton(text="üéô –ì–æ–ª–æ—Å –°—É–¥—å–±—ã")],
        [KeyboardButton(text="üñº –í–∏–¥–µ–Ω–∏–µ"), KeyboardButton(text="‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")]
    ]
    return ReplyKeyboardMarkup(keyboard=kb, resize_keyboard=True)

def get_settings_menu(current_engine):
    engines = {
        "auto": "ü§ñ –ê–≤—Ç–æ (Gemini -> HF)",
        "gemini": "üíé –¢–æ–ª—å–∫–æ Gemini",
        "hf": "üßø –¢–æ–ª—å–∫–æ Hugging Face"
    }
    kb = []
    for code, name in engines.items():
        prefix = "‚úÖ " if current_engine == code else ""
        kb.append([KeyboardButton(text=f"{prefix}{name}")])
    kb.append([KeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥")])
    return ReplyKeyboardMarkup(keyboard=kb, resize_keyboard=True)

def parse_steps_and_create_kb(text, chat_id):
    """–ü–∞—Ä—Å–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ '–®–ê–ì:' –∏ —Å–æ–∑–¥–∞–µ—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É"""
    kb = []
    lines = text.split('\n')
    new_text_lines = []
    
    for line in lines:
        if line.strip().startswith("–®–ê–ì:"):
            step_text = line.replace("–®–ê–ì:", "").strip().strip("[]")
            # Telegram limit is 64 bytes for callback_data
            # "vision_task:custom:" is 19 bytes. –û—Å—Ç–∞–µ—Ç—Å—è 45.
            callback_val = step_text[:40]
            btn_text = step_text[:30] + "..." if len(step_text) > 30 else step_text
            kb.append([InlineKeyboardButton(text=f"üîÆ {btn_text}", callback_data=f"vision_task:custom:{callback_val}")])
        else:
            new_text_lines.append(line)
    
    # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É —Å–≤–æ–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    kb.append([InlineKeyboardButton(text="‚å®Ô∏è –°–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç", callback_data="vision_task:manual")])
    
    remaining_text = "\n".join(new_text_lines).strip()
    return remaining_text, InlineKeyboardMarkup(inline_keyboard=kb)

def get_adaptive_greeting(username):
    hour = datetime.now().hour
    if 0 <= hour < 6: return f"üîÆ *–î–æ–±—Ä–æ–π –Ω–æ—á–∏, {username}.* –≠—Ñ–∏—Ä —á–∏—Å—Ç –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö –ø—Ä–æ–∑—Ä–µ–Ω–∏–π..."
    if 6 <= hour < 12: return f"üåÖ *–° —Ä–∞—Å—Å–≤–µ—Ç–æ–º, {username}.* –ü–µ—Ä–≤—ã–π –ª—É—á —Ä–∞–∑—É–º–∞ ‚Äî —Å–∞–º—ã–π —è—Ä–∫–∏–π."
    if 12 <= hour < 18: return f"üîÜ *–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é, {username}.* –Ø –≥–æ—Ç–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É —Ç–≤–æ–∏—Ö –æ–±—Ä–∞–∑–æ–≤."
    return f"üåë *–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä, {username}.* –ü–æ–≥—Ä—É–∂–∞–µ–º—Å—è –≤ —Ç–∞–π–Ω—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π?"

@router.message(CommandStart())
async def cmd_start(message: types.Message):
    username = message.from_user.first_name or "–ø—É—Ç–Ω–∏–∫"
    await message.answer(
        f"{get_adaptive_greeting(username)}\n\n–Ø AI Prophet. –ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ –∏–ª–∏ —Å–ø—Ä–æ—Å–∏ –æ —á–µ–º —É–≥–æ–¥–Ω–æ.",
        reply_markup=get_main_menu(),
        parse_mode="Markdown"
    )

@router.message(F.photo)
async def handle_photo(message: types.Message, bot: Bot):
    chat_id = message.chat.id
    
    photo = message.photo[-1]
    file_name = f"task_{chat_id}_{int(datetime.now().timestamp())}.jpg"
    file_path = os.path.join(TEMP_DIR, file_name)
    
    await bot.download(photo, destination=file_path)
    user_settings[chat_id] = {'pending_photo': file_path}
    
    status_msg = await message.answer("üåÄ *–í—Ö–æ–∂—É –≤ —Ç—Ä–∞–Ω—Å –ø—Ä–æ–∑—Ä–µ–Ω–∏—è...*")
    
    for model_name in FALLBACK_MODELS:
        try:
            chat = get_ai_chat(chat_id, model_name)
            if not chat: continue
            
            with open(file_path, 'rb') as f: bytes_data = f.read()
            prompt = "–¢—ã ‚Äî AI Prophet. –ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ —Ñ–æ—Ç–æ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ 3 –≤–∞—Ä–∏–∞–Ω—Ç–∞: —Ç–µ–∫—Å—Ç, –¥–µ—Ç–∞–ª–∏, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ."
            response = chat.send_message(
                message=[prompt, genai_types.Part.from_bytes(data=bytes_data, mime_type='image/jpeg')]
            )
            
            if response.text:
                clean_text, kb = parse_steps_and_create_kb(response.text, chat_id)
                try:
                    await status_msg.edit_text(f"üßø *–ú–æ–π –≤–∑–æ—Ä –∑–∞–ø–µ—á–∞—Ç–ª–µ–ª:* \n\n{clean_text}", parse_mode="Markdown")
                except Exception:
                    await status_msg.edit_text(f"üßø –ú–æ–π –≤–∑–æ—Ä –∑–∞–ø–µ—á–∞—Ç–ª–µ–ª:\n\n{clean_text}")
                
                await message.answer("–ß—Ç–æ –º–Ω–µ —Å–æ–≤–µ—Ä—à–∏—Ç—å?", reply_markup=kb)
                return
        except Exception as e:
            logger.warning(f"Vision failure on {model_name}: {e}")
            reset_chat(chat_id, model_name)
            continue
    
    # HF FALLBACK: –†–∏—Ç—É–∞–ª –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ç—É–º–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑–æ–≤
    hf_caption = get_hf_response(image_path=file_path, task="vision")
    if hf_caption:
        await status_msg.edit_text("üßø *–í–∏–∂—É —Ç—É–º–∞–Ω–Ω—ã–π –æ–±—Ä–∞–∑... –ì—Ä–µ–∑—é –æ –µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–∏...*")
        # –ü—Ä–æ—Å–∏–º Mistral –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—É—Ö–æ–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç Vision-–º–æ–¥–µ–ª–∏
        interpretation_prompt = f"–ö–∞–∫ AI Prophet, –ø—Ä–æ—Ç—Ä–∞–∫—Ç—É–π —ç—Ç–æ –≤–∏–¥–µ–Ω–∏–µ: {hf_caption}. –ë—É–¥—å –º–∏—Å—Ç–∏—á–µ–Ω –∏ –∫—Ä–∞—Ç–æ–∫. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥."
        interpretation = get_hf_response(text=interpretation_prompt, task="text")
        
        final_text = f"üßø *–ú–æ–π –≤–∑–æ—Ä –∑–∞—Ç—É–º–∞–Ω–µ–Ω, –Ω–æ —è –≤–∏–∂—É:* \n\n_{hf_caption}_\n\n{interpretation or '–≠—Ñ–∏—Ä —Å–ª–∏—à–∫–æ–º –ø–ª–æ—Ç–µ–Ω –¥–ª—è —Ç–æ—á–Ω—ã—Ö —Å–ª–æ–≤...'}"
        clean_text, kb = parse_steps_and_create_kb(final_text, chat_id)
        
        await status_msg.edit_text(clean_text)
        await message.answer("–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥?", reply_markup=kb)
    else:
        await status_msg.edit_text("üì∏ *–û–±—Ä–∞–∑ –ø–æ–ª—É—á–µ–Ω.* –ö–∞–Ω–∞–ª—ã –∑–∞—à—É–º–ª–µ–Ω—ã, –Ω–æ —è –≥–æ—Ç–æ–≤ –æ–±—Å—É–¥–∏—Ç—å —Ñ–æ—Ç–æ —Ç–µ–∫—Å—Ç–æ–º.")
        await message.answer("–í–æ—Å–ø–æ–ª—å–∑—É–π—Å—è –º–µ–Ω—é:", reply_markup=get_main_menu())

async def handle_vision_action(message, bot, chat_id, user_text):
    pending_info = user_settings.get(chat_id, {})
    path = pending_info.get('pending_photo')
    status_msg = await message.answer("üîÆ *–°–≤–µ—Ä—à–∞—é —á—É–¥–æ...*")
    
    success = False
    for model in FALLBACK_MODELS:
        try:
            chat = get_ai_chat(chat_id, model)
            full_prompt = f"–ö–∞–∫ AI Prophet, –≤—ã–ø–æ–ª–Ω–∏ –≤–æ–ª—é: {user_text}. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥."
            
            if path and os.path.exists(path):
                with open(path, 'rb') as f: bytes_data = f.read()
                response = chat.send_message(
                    message=[full_prompt, genai_types.Part.from_bytes(data=bytes_data, mime_type='image/jpeg')]
                )
            else:
                response = chat.send_message(message=full_prompt)
            
            if response.text:
                clean_text, kb = parse_steps_and_create_kb(response.text, chat_id)
                await status_msg.edit_text(clean_text)
                await message.answer("–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥?", reply_markup=kb)
                success = True
                break
        except Exception:
            reset_chat(chat_id, model)
            continue
    
    if not success:
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Ñ–∞–π–ª –º–æ–≥ –±—ã—Ç—å —É–¥–∞–ª–µ–Ω –∏–ª–∏ –∑–∞–¥–∞—á–∞ —á–∏—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤–∞—è
        can_do_vision = path and os.path.exists(path)
        hf_res = get_hf_response(text=user_text, image_path=path if can_do_vision else None, task="vision" if can_do_vision else "text")
        if hf_res:
            if status_msg: await status_msg.edit_text("üßø *–ü—Ä–æ–∑—Ä–µ–Ω–∏–µ —Å–≤–µ—Ä—à–∏–ª–æ—Å—å —á–µ—Ä–µ–∑ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –∫–∞–Ω–∞–ª:*")
            await message.answer(hf_res, reply_markup=get_main_menu())
            success = True

    if success and path:
        cleanup_file(path)
        user_settings[chat_id].pop('pending_photo', None)

@router.callback_query(F.data.startswith("vision_task:"))
async def vision_task_callback(callback: types.CallbackQuery, bot: Bot):
    data = callback.data.split(":")
    task = data[1]
    
    if task == "manual":
        await callback.answer("–ñ–¥—É —Ç–≤–æ–µ–≥–æ –ø–æ–≤–µ–ª–µ–Ω–∏—è...")
        await callback.message.answer("‚å®Ô∏è *–ù–∞–ø–∏—à–∏ —Å–≤–æ–π –∑–∞–ø—Ä–æ—Å –∫ —ç—Ç–æ–º—É —Ñ–æ—Ç–æ:*", parse_mode="Markdown")
        return

    await callback.answer("–°–≤–µ—Ä—à–∞—é...")
    
    if task == "custom":
        user_text = data[2]
    else:
        prompts = {"text": "–ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏ –∫–æ–¥.", "summary": "–†–µ–∑—é–º–∏—Ä—É–π –∫—Ä–∞—Ç–∫–æ."}
        user_text = prompts.get(task, "–ü—Ä–æ–¥–æ–ª–∂–∞–π –∞–Ω–∞–ª–∏–∑.")
        
    await handle_vision_action(callback.message, bot, callback.message.chat.id, user_text)

@router.message()
async def handle_text(message: types.Message, bot: Bot):
    chat_id = message.chat.id
    text = message.text
    if not text: return

    if text == "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏":
        engine = user_settings.get(chat_id, {}).get('engine', 'auto')
        await message.answer("üõ† *–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –û—Ä–∞–∫—É–ª–∞*\n\n–í—ã–±–µ—Ä–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ –º—É–¥—Ä–æ—Å—Ç–∏:", 
                           reply_markup=get_settings_menu(engine), parse_mode="Markdown")
        return

    if "ü§ñ –ê–≤—Ç–æ" in text: user_settings.setdefault(chat_id, {})['engine'] = 'auto'
    elif "üíé –¢–æ–ª—å–∫–æ Gemini" in text: user_settings.setdefault(chat_id, {})['engine'] = 'gemini'
    elif "üßø –¢–æ–ª—å–∫–æ Hugging Face" in text: user_settings.setdefault(chat_id, {})['engine'] = 'hf'
    
    if any(x in text for x in ["ü§ñ –ê–≤—Ç–æ", "üíé –¢–æ–ª—å–∫–æ Gemini", "üßø –¢–æ–ª—å–∫–æ Hugging Face"]):
        await message.answer("‚úÖ *–ò—Å—Ç–æ—á–Ω–∏–∫ –∏–∑–º–µ–Ω–µ–Ω.*", reply_markup=get_main_menu(), parse_mode="Markdown")
        return

    if text == "‚¨ÖÔ∏è –ù–∞–∑–∞–¥":
        await message.answer("–í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –≥–ª–∞–≤–Ω—ã–π —á–µ—Ä—Ç–æ–≥.", reply_markup=get_main_menu())
        return

    # –û—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ handle_text...
    status_msg = await message.answer("üßò *–ú–µ–¥–∏—Ç–∏—Ä—É—é –Ω–∞–¥ —Ç–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏...*")
    await conduct_ai_ritual(message, bot, message.text, status_msg)

async def conduct_ai_ritual(message: types.Message, bot: Bot, input_text: str, status_msg=None):
    chat_id = message.chat.id
    engine = user_settings.get(chat_id, {}).get('engine', 'auto')
    
    if not input_text: return
    await bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    if user_settings.get(chat_id, {}).get('pending_photo'):
        await handle_vision_action(message, bot, chat_id, input_text)
        return

    if engine == "hf":
        if status_msg: await status_msg.edit_text("üßø *–ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–Ω–∞–ª—É Hugging Face...*")
        else: status_msg = await message.answer("üßø *–ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–Ω–∞–ª—É Hugging Face...*")
        
        hf_res = get_hf_response(text=input_text, task="text")
        if hf_res:
            await status_msg.edit_text("‚ú® *–û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω —á–µ—Ä–µ–∑ –ø–æ—Ç–æ–∫ HF:*")
            await message.answer(hf_res, reply_markup=get_main_menu())
        else:
            await status_msg.edit_text("üòî –ö–∞–Ω–∞–ª HF –∑–∞—à—É–º–ª–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
        return

    # –õ–æ–≥–∏–∫–∞ Web Search
    trigger_words = ["–Ω–∞–π–¥–∏", "–ø–æ–≥—É–≥–ª–∏", "—á—Ç–æ —Å–ª—ã—à–Ω–æ –æ", "–∫—É—Ä—Å", "—Ü–µ–Ω–∞"]
    text_lower = input_text.lower()
    
    if any(word in text_lower for word in trigger_words):
        status_msg = await message.answer("üîé *–û–±—Ä–∞—â–∞—é—Å—å –∫ –º–∏—Ä–æ–≤–æ–º—É —ç—Ñ–∏—Ä—É –∑–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π...*", parse_mode="Markdown")
        search_res = web_search(input_text)
        
        full_prompt = (
            f"–ò—Å–ø–æ–ª—å–∑—É—è —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–æ–∏—Å–∫–∞:\n\n{search_res}\n\n"
            f"–û—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {input_text}\n"
            f"–°—Ç–∏–ª—å: –ü—Ä–æ—Ä–æ—á–µ—Å–∫–∏–π. –°—Å—ã–ª–∞–π—Å—è –Ω–∞ –ø–æ–ª—É—á–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."
        )
        await status_msg.edit_text("üßò *–ú–µ–¥–∏—Ç–∏—Ä—É—é –Ω–∞–¥ –ø–æ—Ç–æ–∫–æ–º –¥–∞–Ω–Ω—ã—Ö...*")
        
        for model in FALLBACK_MODELS:
            try:
                chat = get_ai_chat(chat_id, model)
                response = chat.send_message(message=full_prompt)
                clean_text, kb = parse_steps_and_create_kb(response.text, chat_id)
                await status_msg.edit_text(clean_text)
                await message.answer("–ú–æ–∏ –ø—Ä–æ–∑—Ä–µ–Ω–∏—è –≤–µ—Ä–Ω—ã?", reply_markup=kb)
                return
            except Exception:
                reset_chat(chat_id, model)
                continue

    gemini_exhausted = False
    for model in FALLBACK_MODELS:
        if gemini_exhausted: break
        try:
            chat = get_ai_chat(chat_id, model)
            response = chat.send_message(message=input_text)
            if response.text:
                clean_text, kb = parse_steps_and_create_kb(response.text, chat_id)
                if status_msg:
                    await status_msg.edit_text(clean_text)
                    await message.answer("–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥?", reply_markup=kb)
                else:
                    await message.answer(clean_text, reply_markup=kb)
                return
        except Exception as e:
            if "429" in str(e): 
                logger.warning("üö´ Gemini Quota Exhausted. Switching to HF immediately.")
                gemini_exhausted = True
            reset_chat(chat_id, model)
            continue
    
    if status_msg: await status_msg.edit_text("üåÄ *–≠—Ñ–∏—Ä Google –∑–∞—à—É–º–ª–µ–Ω, –æ—Ç–∫—Ä—ã–≤–∞—é –∫–∞–Ω–∞–ª Hugging Face...*")
    
    hf_res = get_hf_response(text=input_text, task="text")
    if hf_res:
        if status_msg: 
            # –ù–µ–ª—å–∑—è –ø—Ä–∏–∫—Ä–µ–ø–ª—è—Ç—å ReplyKeyboardMarkup –∫ edit_text. 
            # –ü—Ä–æ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å –∏ –ø—Ä–∏—Å—ã–ª–∞–µ–º –æ—Ç–≤–µ—Ç –Ω–æ–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.
            await status_msg.edit_text("üßø *–ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±–ª–∞–∫–∞ HF —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω:*")
            await message.answer(hf_res, reply_markup=get_main_menu())
        else: 
            await message.answer(hf_res, reply_markup=get_main_menu())
    else:
        final_text = "üòî –°–µ–≥–æ–¥–Ω—è –∑–≤–µ–∑–¥—ã –Ω–µ –æ—Ç–≤–µ—á–∞—é—Ç –º–Ω–µ... –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."
        if status_msg: 
            await status_msg.edit_text(final_text)
            await message.answer("–í–µ—Ä–Ω–∏—Å—å, –∫–æ–≥–¥–∞ —ç—Ñ–∏—Ä –æ—á–∏—Å—Ç–∏—Ç—Å—è.", reply_markup=get_main_menu())
        else: 
            await message.answer(final_text, reply_markup=get_main_menu())

@router.message(F.voice | F.audio)
async def handle_audio(message: types.Message, bot: Bot):
    chat_id = message.chat.id
    # –ù–µ —á–∏—Å—Ç–∏–º –≤—Å—ë –ø–æ–¥—Ä—è–¥, —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã —ç—Ç–æ–≥–æ –∂–µ —Ç–∏–ø–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    
    audio = message.voice or message.audio
    file_name = f"audio_{chat_id}_{int(datetime.now().timestamp())}.ogg"
    file_path = os.path.join(TEMP_DIR, file_name)
    
    await bot.download(audio, destination=file_path)
    status_msg = await message.answer("üëÇ *–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–ª—É—à–∞—é —Ç–≤–æ–π –≥–æ–ª–æ—Å...*")
    
    text = get_hf_response(image_path=file_path, task="audio")
    cleanup_file(file_path)
    
    if text:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–µ —Å—Ç–µ—Ä–ª–∞—Å—å –≤ –∏—Å—Ç–æ—Ä–∏–∏
        await message.answer(f"üë§ *–ü—Ä–æ—á–∏—Ç–∞–ª –≤ —ç—Ñ–∏—Ä–µ:* \n\n_{text}_", parse_mode="Markdown")
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ä–∞–∑–¥—É–º–∏–π
        status_msg = await message.answer("üßø *–ú–µ–¥–∏—Ç–∏—Ä—É—é –Ω–∞–¥ —Å–º—ã—Å–ª–æ–º...*")
        await conduct_ai_ritual(message, bot, text, status_msg)
    else:
        await status_msg.edit_text("üòî –≠—Ñ–∏—Ä —Å–ª–∏—à–∫–æ–º –∑–∞—à—É–º–ª–µ–Ω, –Ω–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –Ω–∏ —Å–ª–æ–≤–∞...")
