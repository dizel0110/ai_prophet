import os
import logging
import asyncio
import random
import glob
from datetime import datetime
from aiogram import Router, types, Bot, F
from aiogram.enums import ChatAction
from aiogram.filters import Command, CommandStart
from aiogram.types import WebAppInfo, ReplyKeyboardMarkup, KeyboardButton, InlineKeyboardMarkup, InlineKeyboardButton
from core.ai_engine import get_ai_chat, get_client, reset_chat, get_hf_response
from config import FALLBACK_MODELS, TEMP_DIR
from google.genai import types as genai_types

logger = logging.getLogger(__name__)
router = Router()
user_settings = {}

def cleanup_file(path):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
    try:
        if path and os.path.exists(path):
            os.remove(path)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {path}")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {path}: {e}")

def cleanup_user_temp(chat_id):
    """–£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    pattern = os.path.join(TEMP_DIR, f"task_{chat_id}_*")
    for f in glob.glob(pattern):
        cleanup_file(f)
    pattern_audio = os.path.join(TEMP_DIR, f"audio_{chat_id}_*")
    for f in glob.glob(pattern_audio):
        cleanup_file(f)

def get_adaptive_greeting(username):
    hour = datetime.now().hour
    if 0 <= hour < 6: return f"üîÆ *–î–æ–±—Ä–æ–π –Ω–æ—á–∏, {username}.* –≠—Ñ–∏—Ä —á–∏—Å—Ç –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö –ø—Ä–æ–∑—Ä–µ–Ω–∏–π..."
    if 6 <= hour < 12: return f"üåÖ *–° —Ä–∞—Å—Å–≤–µ—Ç–æ–º, {username}.* –ü–µ—Ä–≤—ã–π –ª—É—á —Ä–∞–∑—É–º–∞ ‚Äî —Å–∞–º—ã–π —è—Ä–∫–∏–π."
    if 12 <= hour < 18: return f"üîÜ *–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é, {username}.* –Ø –≥–æ—Ç–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É —Ç–≤–æ–∏—Ö –æ–±—Ä–∞–∑–æ–≤."
    return f"üåë *–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä, {username}.* –ü–æ–≥—Ä—É–∂–∞–µ–º—Å—è –≤ —Ç–∞–π–Ω—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π?"

@router.message(CommandStart())
async def cmd_start(message: types.Message):
    username = message.from_user.first_name or "–ø—É—Ç–Ω–∏–∫"
    web_app_url = "https://dizel0110.github.io/ai_prophet/"
    kb = [[KeyboardButton(text="üì± –û—Ç–∫—Ä—ã—Ç—å Mini App", web_app=WebAppInfo(url=web_app_url))]]
    await message.answer(
        f"{get_adaptive_greeting(username)}\n\n–Ø AI Prophet. –ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ –∏–ª–∏ —Å–ø—Ä–æ—Å–∏ –æ —á–µ–º —É–≥–æ–¥–Ω–æ.",
        reply_markup=ReplyKeyboardMarkup(keyboard=kb, resize_keyboard=True),
        parse_mode="Markdown"
    )

@router.message(F.photo)
async def handle_photo(message: types.Message, bot: Bot):
    chat_id = message.chat.id
    # –ß–∏—Å—Ç–∏–º —Å—Ç–∞—Ä—ã–µ —Ñ–æ—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ
    cleanup_user_temp(chat_id)
    
    photo = message.photo[-1]
    file_name = f"task_{chat_id}_{int(datetime.now().timestamp())}.jpg"
    file_path = os.path.join(TEMP_DIR, file_name)
    
    await bot.download(photo, destination=file_path)
    user_settings[chat_id] = {'pending_photo': file_path}
    
    status_msg = await message.answer("üåÄ *–í—Ö–æ–∂—É –≤ —Ç—Ä–∞–Ω—Å –ø—Ä–æ–∑—Ä–µ–Ω–∏—è...*")
    
    for model_name in FALLBACK_MODELS:
        try:
            chat = get_ai_chat(chat_id, model_name)
            if not chat: continue
            
            with open(file_path, 'rb') as f: bytes_data = f.read()
            prompt = "–¢—ã ‚Äî AI Prophet. –ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ —Ñ–æ—Ç–æ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ 3 –≤–∞—Ä–∏–∞–Ω—Ç–∞: —Ç–µ–∫—Å—Ç, –¥–µ—Ç–∞–ª–∏, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ."
            response = chat.send_message(
                message=[prompt, genai_types.Part.from_bytes(data=bytes_data, mime_type='image/jpeg')]
            )
            
            if response.text:
                await status_msg.edit_text(f"üßø *–ú–æ–π –≤–∑–æ—Ä –∑–∞–ø–µ—á–∞—Ç–ª–µ–ª ({model_name}):*\n\n{response.text}", parse_mode="Markdown")
                kb = [
                    [InlineKeyboardButton(text="üìù –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç/–∫–æ–¥", callback_data="vision_task:text")],
                    [InlineKeyboardButton(text="üìä –†–µ–∑—é–º–∏—Ä–æ–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ", callback_data="vision_task:summary")]
                ]
                await message.answer("–ß—Ç–æ –º–Ω–µ —Å–æ–≤–µ—Ä—à–∏—Ç—å?", reply_markup=InlineKeyboardMarkup(inline_keyboard=kb))
                return
        except Exception as e:
            logger.warning(f"Vision failure on {model_name}: {e}")
            reset_chat(chat_id, model_name)
            continue
    
    # HF FALLBACK
    hf_res = get_hf_response(image_path=file_path, task="vision")
    if hf_res:
        await status_msg.edit_text(f"üßø *–û—Ç–≤–µ—Ç –æ—Ç Vision-–º–æ–¥–µ–ª–∏ HF:*\n\n{hf_res}")
    else:
        await status_msg.edit_text("üì∏ *–û–±—Ä–∞–∑ –ø–æ–ª—É—á–µ–Ω.* –ö–∞–Ω–∞–ª—ã –∑–∞—à—É–º–ª–µ–Ω—ã, –Ω–æ —è –≥–æ—Ç–æ–≤ –æ–±—Å—É–¥–∏—Ç—å —Ñ–æ—Ç–æ —Ç–µ–∫—Å—Ç–æ–º.")

async def handle_vision_action(message, bot, chat_id, user_text):
    pending_info = user_settings.get(chat_id, {})
    path = pending_info.get('pending_photo')
    status_msg = await message.answer("üîÆ *–°–≤–µ—Ä—à–∞—é —á—É–¥–æ...*")
    
    success = False
    for model in FALLBACK_MODELS:
        try:
            chat = get_ai_chat(chat_id, model)
            full_prompt = f"–ö–∞–∫ AI Prophet, –≤—ã–ø–æ–ª–Ω–∏ –≤–æ–ª—é: {user_text}. –í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥."
            
            if path and os.path.exists(path):
                with open(path, 'rb') as f: bytes_data = f.read()
                response = chat.send_message(
                    message=[full_prompt, genai_types.Part.from_bytes(data=bytes_data, mime_type='image/jpeg')]
                )
            else:
                response = chat.send_message(message=full_prompt)
            
            await status_msg.edit_text(response.text)
            success = True
            break
        except Exception:
            reset_chat(chat_id, model)
            continue
    
    if not success:
        hf_res = get_hf_response(text=user_text, image_path=path, task="vision" if path else "text")
        if hf_res:
            await status_msg.edit_text(f"üßø *–û—Ç–≤–µ—Ç –∏–∑ –æ–±–ª–∞–∫–∞ HF:*\n\n{hf_res}")
            success = True

    if success and path:
        cleanup_file(path)
        user_settings[chat_id].pop('pending_photo', None)

@router.callback_query(F.data.startswith("vision_task:"))
async def vision_task_callback(callback: types.CallbackQuery, bot: Bot):
    task = callback.data.split(":")[1]
    prompts = {"text": "–ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏ –∫–æ–¥.", "summary": "–†–µ–∑—é–º–∏—Ä—É–π –∫—Ä–∞—Ç–∫–æ."}
    await callback.answer("–°–≤–µ—Ä—à–∞—é...")
    await handle_vision_action(callback.message, bot, callback.message.chat.id, prompts[task])

@router.message()
async def handle_text(message: types.Message, bot: Bot):
    chat_id = message.chat.id
    if not message.text: return
    await bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    if user_settings.get(chat_id, {}).get('pending_photo'):
        await handle_vision_action(message, bot, chat_id, message.text)
        return

    for model in FALLBACK_MODELS:
        try:
            chat = get_ai_chat(chat_id, model)
            response = chat.send_message(message=message.text)
            await message.answer(f"{response.text}\n\n_–ß—Ç–æ –µ—â–µ —Ö–æ—á–µ—à—å —É–∑–Ω–∞—Ç—å?_", parse_mode="Markdown")
            return
        except Exception:
            reset_chat(chat_id, model)
            continue
    
    hf_res = get_hf_response(text=message.text, task="text")
    if hf_res:
        await message.answer(f"üåÄ *Gemini –º–æ–ª—á–∏—Ç, –Ω–æ HF —è–≤–∏–ª –æ—Ç–≤–µ—Ç:*\n\n{hf_res}")
    else:
        await message.answer("üòî –°–µ–≥–æ–¥–Ω—è –∑–≤–µ–∑–¥—ã –Ω–µ –æ—Ç–≤–µ—á–∞—é—Ç –º–Ω–µ...")

@router.message(F.voice | F.audio)
async def handle_audio(message: types.Message, bot: Bot):
    chat_id = message.chat.id
    cleanup_user_temp(chat_id) # –ß–∏—Å—Ç–∏–º —Å—Ç–∞—Ä–æ–µ –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
    
    audio = message.voice or message.audio
    file_name = f"audio_{chat_id}_{int(datetime.now().timestamp())}.ogg"
    file_path = os.path.join(TEMP_DIR, file_name)
    
    await bot.download(audio, destination=file_path)
    status_msg = await message.answer("üëÇ *–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–ª—É—à–∞—é —Ç–≤–æ–π –≥–æ–ª–æ—Å...*")
    
    text = get_hf_response(image_path=file_path, task="audio")
    cleanup_file(file_path)
    
    if text:
        await status_msg.edit_text(f"üë§ *–¢–≤–æ–∏ —Å–ª–æ–≤–∞:* \n\n_{text}_\n\n_–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é..._", parse_mode="Markdown")
        message.text = text
        await handle_text(message, bot)
    else:
        await status_msg.edit_text("üòî –ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å.")
